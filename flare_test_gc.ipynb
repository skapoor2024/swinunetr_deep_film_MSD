{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is to get scores on the test dataset and check it on flare2021 test grand challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import nibabel as nib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gg_tools import get_test_txt_loader, get_test_data_loader, dice_score, TEMPLATE, get_key, NUM_CLASS, ORGAN_NAME, merge_label_v1, save_result, organ_post_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.inferers import sliding_window_inference\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader,test_transform,args,post_process=False):\n",
    "\n",
    "    model.eval()\n",
    "    i = 0\n",
    "    for batch in tqdm(test_loader):\n",
    "\n",
    "        if(args.model_type == 'film'):\n",
    "            image, name, prompt = batch['image'].to(args.device), batch['name'], batch['prompt']\n",
    "        else:\n",
    "            image, name = batch['image'].to(args.device), batch['name']\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            if(args.model_type == 'film'):\n",
    "                predictor = lambda image_patch:model(image_patch,prompt)\n",
    "                pred = sliding_window_inference(image, (args.roi_x, args.roi_y, args.roi_z), 1, predictor)\n",
    "            else:\n",
    "                pred = sliding_window_inference(image, (args.roi_x, args.roi_y, args.roi_z), 1, model)\n",
    "            pred_sigmoid = torch.nn.functional.sigmoid(pred)\n",
    "        \n",
    "        #now squeeze it  threshold with 0.5 ,  convert it into numpy, post_process it if needed , convert into tensor and store in batch['result']\n",
    "        pred_sigmoid = torch.squeeze(pred_sigmoid)\n",
    "        pred_mask = torch.where(pred_sigmoid>=0.5,1,0).to(torch.uint8).cpu().numpy()\n",
    "\n",
    "        template_key = get_key(name[0]) #since for val_loader we have just 1 .\n",
    "        organ_list = TEMPLATE[template_key]\n",
    "\n",
    "        if post_process:\n",
    "            pred_mask = organ_post_process(pred_mask,organ_list)\n",
    "        \n",
    "        pred_mask_merged = merge_label_v1(pred_mask,name[0])\n",
    "        pred_mask_merged = pred_mask_merged.astype(np.uint8)\n",
    "        #convert it into tensor and save\n",
    "        batch['result'] = torch.from_numpy(np.expand_dims(pred_mask_merged,axis=0))\n",
    "        \n",
    "        #for path get the folder from name\n",
    "        file_name = name[0].split('.')[0]\n",
    "        subfold_path = file_name.split('/')[1]\n",
    "        save_dir = os.path.join(args.os_save_fold,subfold_path)\n",
    "        #print(save_dir,file_name)\n",
    "        save_result(batch,test_transform,save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_clip = SimpleNamespace(\n",
    "    space_x = 1.5,\n",
    "    space_y = 1.5,\n",
    "    space_z = 1.5,\n",
    "    roi_x = 96,\n",
    "    roi_y = 96,\n",
    "    roi_z = 96,\n",
    "    num_samples = 2,\n",
    "    data_root_path = '/blue/kgong/s.kapoor/language_guided_segmentation/CLIP-Driven-Universal-Model/',\n",
    "    data_txt_path = './dataset/dataset_list/',\n",
    "    batch_size = 4,\n",
    "    num_workers = 8,\n",
    "    a_min = -175,\n",
    "    a_max = 250,\n",
    "    b_min = 0.0,\n",
    "    b_max = 1.0,\n",
    "    dataset_list = ['flaretest'], #here it is used to vaidate the model\n",
    "    NUM_CLASS = NUM_CLASS,\n",
    "    backbone = 'swinunetr',\n",
    "    trans_encoding = 'word_embedding',\n",
    "    pretrain = './swinunetr.pth',\n",
    "    lr = 4e-4,\n",
    "    weight_decay = 1e-5,\n",
    "    precomputed_prompt_path = './embeddings_template_flare.pkl',\n",
    "    word_embedding = './pretrained_weights/txt_encoding.pth',\n",
    "    dist = False,\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    model_type = None,\n",
    "    file_name = 'universal_flaretest.txt',\n",
    "    os_save_fold = './flaretest/universal_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.Universal_model import Universal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the model\n",
    "model = Universal_model(img_size=(args_clip.roi_x, args_clip.roi_y, args_clip.roi_z),\n",
    "                in_channels=1,\n",
    "                out_channels=32,\n",
    "                backbone=args_clip.backbone,\n",
    "                encoding=args_clip.trans_encoding\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying to match the keys from the author's weights\n",
    "checkpoint = torch.load(args_clip.pretrain)\n",
    "store_dict = model.state_dict()\n",
    "load_dict = checkpoint['net']\n",
    "for key,value in load_dict.items():\n",
    "\n",
    "    #print(key)\n",
    "    key = '.'.join(key.split('.')[1:]) #remove module\n",
    "    if 'swinViT' in key or 'encoder' in key or 'decoder' in key: #add backbone context;\n",
    "        key ='.'.join(['backbone',key])\n",
    "    #print(key)\n",
    "    if key in store_dict.keys():\n",
    "        store_dict[key]=value\n",
    "    else:\n",
    "        print(key)\n",
    "model.load_state_dict(store_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(args_clip.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test len 90\n"
     ]
    }
   ],
   "source": [
    "clip_loader,clip_transform = get_test_data_loader(args_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [11:51<00:00,  7.91s/it]\n"
     ]
    }
   ],
   "source": [
    "test(model,clip_loader,clip_transform,args_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_film = SimpleNamespace(\n",
    "    space_x = 1.5,\n",
    "    space_y = 1.5,\n",
    "    space_z = 1.5,\n",
    "    roi_x = 96,\n",
    "    roi_y = 96,\n",
    "    roi_z = 96,\n",
    "    num_samples = 2,\n",
    "    data_root_path = '/blue/kgong/s.kapoor/language_guided_segmentation/CLIP-Driven-Universal-Model/',\n",
    "    data_txt_path = './dataset/dataset_list/',\n",
    "    batch_size = 4,\n",
    "    num_workers = 8,\n",
    "    a_min = -175,\n",
    "    a_max = 250,\n",
    "    b_min = 0.0,\n",
    "    b_max = 1.0,\n",
    "    dataset_list = ['flaretest'],\n",
    "    NUM_CLASS = NUM_CLASS,\n",
    "    backbone = 'swinunetr',\n",
    "    trans_encoding = 'word_embedding',\n",
    "    pretrain = './out/deep_film_total/epoch_380.pth',\n",
    "    lr = 4e-4,\n",
    "    weight_decay = 1e-5,\n",
    "    precomputed_prompt_path = 'embeddings_template_flare.pkl',\n",
    "    dist = False,\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    model_type='film',\n",
    "    file_name='flare_test_test.txt',\n",
    "    os_save_fold = './flaretest/deep_film_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.SwinUNETR_DEEP_FILM import SwinUNETR_DEEP_FILM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_model = SwinUNETR_DEEP_FILM(img_size=(args_film.roi_x, args_film.roi_y, args_film.roi_z),\n",
    "                        in_channels=1,\n",
    "                        out_channels=32,\n",
    "                        precomputed_prompt_path=args_film.precomputed_prompt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_checkpoint = torch.load(args_film.pretrain)\n",
    "store_dict = film_model.state_dict()\n",
    "load_dict = film_checkpoint['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in load_dict.items():\n",
    "\n",
    "    if 'swinViT' in key or 'encoder' in key or 'decoder' in key:\n",
    "        name = '.'.join(key.split('.')[1:])\n",
    "    else:\n",
    "        name = '.'.join(key.split('.')[1:])\n",
    "    if name in store_dict.keys():\n",
    "        store_dict[name]=value\n",
    "    else:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film_model.load_state_dict(store_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_model = film_model.to(args_film.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test len 90\n"
     ]
    }
   ],
   "source": [
    "film_loader,film_transform = get_test_txt_loader(args_film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [11:05<00:00,  7.39s/it]\n"
     ]
    }
   ],
   "source": [
    "test(film_model,film_loader,film_transform,args_film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_0000(folder_path):\n",
    "\n",
    "    for filename in tqdm(os.listdir(folder_path)):\n",
    "        if filename.endswith('.nii.gz'):\n",
    "            new_filename = filename.replace('_0000','')\n",
    "            old_path = os.path.join(folder_path,filename)\n",
    "            new_path = os.path.join(folder_path,new_filename)\n",
    "            os.rename(old_path,new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 2517.14it/s]\n"
     ]
    }
   ],
   "source": [
    "remove_0000(os.path.join(args_clip.os_save_fold,'imagesTs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 2562.36it/s]\n"
     ]
    }
   ],
   "source": [
    "remove_0000(os.path.join(args_film.os_save_fold,'imagesTs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
