{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963891e5-1337-449f-b586-7e9f2dc68c86",
   "metadata": {},
   "source": [
    "## Check data if present in the list is same as that of dataset.json for all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd6b61a-5a0a-4e8c-811d-f6ec7ac91726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88bafa3c-9c16-445a-bc97-40701964d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d7e276d-9808-4c42-8b34-308c225d8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the txt file\n",
    "data_txt_file = './dataset/dataset_list/PAOT_10_inner_val.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f1f7ccd-91f5-4d92-8fbf-437c0cba2468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to each msd folder and get their dataset json file\n",
    "dic = {}\n",
    "msd_folder = './10_Decathlon'\n",
    "for fold in os.listdir(msd_folder):\n",
    "    fold_path = os.path.join(msd_folder,fold)\n",
    "    if os.path.isdir(fold_path) and fold[4:6] in ['03','06','10','07','08','09']:\n",
    "        json_path = os.path.join(fold_path,'dataset.json')\n",
    "        #print(json_path)\n",
    "        if os.path.exists(json_path):\n",
    "            dic[fold_path]=json_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abc789eb-c236-4cd4-932f-0eb113c446de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'./10_Decathlon/Task09_Spleen': './10_Decathlon/Task09_Spleen/dataset.json',\n",
       " './10_Decathlon/Task07_Pancreas': './10_Decathlon/Task07_Pancreas/dataset.json',\n",
       " './10_Decathlon/Task03_Liver': './10_Decathlon/Task03_Liver/dataset.json',\n",
       " './10_Decathlon/Task06_Lung': './10_Decathlon/Task06_Lung/dataset.json',\n",
       " './10_Decathlon/Task10_Colon': './10_Decathlon/Task10_Colon/dataset.json',\n",
       " './10_Decathlon/Task08_HepaticVessel': './10_Decathlon/Task08_HepaticVessel/dataset.json'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6769d820-efa4-4079-90b9-85197a50cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#well we have the files. We have to remove the '.' file from each folder\n",
    "#also need to rename task with Dataset.\n",
    "nnunet_raw = '/blue/kgong/s.kapoor/language_guided_segmentation/CLIP-Driven-Universal-Model_MSD_only/nnUNet_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc80da24-903c-4dd5-828f-efea4affa023",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_name = 'Task'\n",
    "new_name = 'Dataset0'\n",
    "for fold in os.listdir(nnunet_raw):\n",
    "    if old_name in fold:\n",
    "        source_path = os.path.join(nnunet_raw,fold)\n",
    "        dst_path = os.path.join(nnunet_raw,fold.replace(old_name,new_name))\n",
    "        os.rename(source_path,dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3dd08e3-4e4f-4c13-9204-8a85927db836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 10.45it/s]\n"
     ]
    }
   ],
   "source": [
    "new_name2 = 'Dataset'\n",
    "#now remove the . files\n",
    "for fold in tqdm.tqdm(os.listdir(nnunet_raw)):\n",
    "    if new_name2 in fold:\n",
    "        fold_path = os.path.join(nnunet_raw,fold)\n",
    "        for subfold in os.listdir(fold_path):\n",
    "            subfold_path = os.path.join(fold_path,subfold)\n",
    "            if os.path.isdir(subfold_path):\n",
    "                for file in os.listdir(subfold_path):\n",
    "                    file_path = os.path.join(subfold_path,file)\n",
    "                    if file.startswith('.') and os.path.isfile(file_path):\n",
    "                        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d18f1da8-01c6-4e72-8bac-aa9db46cc472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 17.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#now add _0000 to eachfile name cause modality.\n",
    "des_fold = 'imagesTr'\n",
    "for fold in tqdm.tqdm(os.listdir(nnunet_raw)):\n",
    "    if new_name2 in fold:\n",
    "        fold_path = os.path.join(nnunet_raw,fold)\n",
    "        for subfold in os.listdir(fold_path):\n",
    "            if not subfold.startswith('.') and des_fold in subfold:\n",
    "                subfold_path = os.path.join(fold_path,subfold)\n",
    "                for filename in os.listdir(subfold_path):\n",
    "                    new_filename = filename[:-7]+'_0000.nii.gz'\n",
    "                    filename_path = os.path.join(subfold_path,filename)\n",
    "                    new_filename_path = os.path.join(subfold_path,new_filename)\n",
    "                    os.rename(filename_path,new_filename_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23931a26-ff68-4fad-a1de-d7d2654a3dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/blue/kgong/s.kapoor/language_guided_segmentation/CLIP-Driven-Universal-Model_MSD_only\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1674488-82e0-4b09-8821-7961d05573e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_dataset_json import generate_dataset_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6510ba1c-6c67-496c-8914-01e3c03c4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 2048.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#first replace the old file with dataset.json as dataset_nnunetv1.json\n",
    "for fold in tqdm.tqdm(os.listdir(nnunet_raw)):\n",
    "    if new_name2 in fold:\n",
    "        fold_path = os.path.join(nnunet_raw,fold)\n",
    "        json_file_path = os.path.join(fold_path,'dataset.json')\n",
    "        new_json_file_path = os.path.join(fold_path,'dataset_nnunetv1.json')\n",
    "        os.rename(json_file_path,new_json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2f6af67-7e1e-4cf9-b777-7131e3f868a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1082.08it/s]\n"
     ]
    }
   ],
   "source": [
    "#now need to create dataset.json file for each dataset. Moreover it should contain the split that is present for the training of the swinunetr.\n",
    "#create dataset.json and then after preprocessing / edit the splits\n",
    "\n",
    "for fold in tqdm.tqdm(os.listdir(nnunet_raw)):\n",
    "    if new_name2 in fold:\n",
    "        fold_path = os.path.join(nnunet_raw,fold)\n",
    "        #from the dataset.json get labels\n",
    "        json_file = os.path.join(fold_path,'dataset_nnunetv1.json')\n",
    "        with open(json_file,'r') as f:\n",
    "            data = json.load(f)\n",
    "        req_labels_in_order = {v:int(k) for k,v in data['labels'].items()}\n",
    "        #print(req_labels_in_order)\n",
    "        num_files = data['numTraining']\n",
    "        #print(num_files)\n",
    "        # train_file_path = os.path.join(fold_path,'imagesTr')\n",
    "        # num_files = len([f for f in os.listdir(train_file_path) if f.endswith('.nii.gz')])\n",
    "        # print(num_files)\n",
    "        output_folder = fold_path\n",
    "        channel_names = {\"0\":\"CT\"}\n",
    "        labels = req_labels_in_order\n",
    "        num_training_cases = num_files\n",
    "        file_ending = '.nii.gz'\n",
    "        dataset_name = fold.split('_')[1] + '_from_MSD'\n",
    "        generate_dataset_json(output_folder=output_folder,\n",
    "                              channel_names = channel_names,\n",
    "                              labels = labels,\n",
    "                              num_training_cases = num_training_cases,\n",
    "                              file_ending = file_ending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0c880bc-f719-4c25-8d03-4d697cc252b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run to preprocess the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41af56ee-4f89-4a9d-a435-94e5ad4b8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now create the custom splits.json file for each dataset.\n",
    "nnunet_preprocessed = '/blue/kgong/s.kapoor/language_guided_segmentation/CLIP-Driven-Universal-Model_MSD_only/nnUNet_preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4961731c-2723-4a20-9ecd-3b9a739cd2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the dictionary of the requried folders\n",
    "dic = {}\n",
    "for fold in os.listdir(nnunet_preprocessed):\n",
    "    fold_path = os.path.join(nnunet_preprocessed,fold)\n",
    "    if os.path.isdir(fold_path) and fold[7:10] in ['003','006','007','008','009','010']:\n",
    "        dic[fold]={'train':[],'val':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d49c842-fa6f-4cf1-b746-664e84948941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dataset009_Spleen': {'train': [], 'val': []},\n",
       " 'Dataset007_Pancreas': {'train': [], 'val': []},\n",
       " 'Dataset008_HepaticVessel': {'train': [], 'val': []},\n",
       " 'Dataset010_Colon': {'train': [], 'val': []},\n",
       " 'Dataset006_Lung': {'train': [], 'val': []},\n",
       " 'Dataset003_Liver': {'train': [], 'val': []}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0d8cfb5-ff99-42ec-8601-1c56d93a066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mappiong from Dataset to task\n",
    "val_txt_file = './dataset/dataset_list/PAOT_10_inner_val.txt'\n",
    "dic_map = {}\n",
    "with open(train_txt_file,'r') as file:\n",
    "    for line in file:\n",
    "\n",
    "        line = line.strip()\n",
    "        fold = line.split()[0].split('/')[1]\n",
    "        if fold not in dic_map.keys():\n",
    "            dic_map[fold] = fold.replace(old_name,new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd4fa3ab-f3ca-4da6-8d6f-3196b82ec13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Task03_Liver': 'Dataset003_Liver',\n",
       " 'Task06_Lung': 'Dataset006_Lung',\n",
       " 'Task07_Pancreas': 'Dataset007_Pancreas',\n",
       " 'Task08_HepaticVessel': 'Dataset008_HepaticVessel',\n",
       " 'Task09_Spleen': 'Dataset009_Spleen',\n",
       " 'Task10_Colon': 'Dataset010_Colon'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01825b2f-9da8-42fa-81ef-0b61c751f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the list of train files\n",
    "train_txt_file = './dataset/dataset_list/PAOT_10_inner_train.txt'\n",
    "with open(train_txt_file,'r') as file:\n",
    "\n",
    "    for line in file:\n",
    "\n",
    "        line = line.strip()\n",
    "        gg = line.split()[0].split('/')\n",
    "        fold = gg[1]\n",
    "        act_fold = dic_map[fold]\n",
    "        file = gg[-1].split('.')[0]\n",
    "        dic[act_fold]['train'].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "021c32ba-a363-4395-abfd-4dd5209e041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the list of val files\n",
    "val_txt_file = './dataset/dataset_list/PAOT_10_inner_val.txt'\n",
    "with open(val_txt_file,'r') as file:\n",
    "\n",
    "    for line in file:\n",
    "\n",
    "        line = line.strip()\n",
    "        gg = line.split()[0].split('/')\n",
    "        fold = gg[1]\n",
    "        act_fold = dic_map[fold]\n",
    "        file = gg[-1].split('.')[0]\n",
    "        dic[act_fold]['val'].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae92c3f7-d2b5-4c24-8b9a-ffb06e66003d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Dataset009_Spleen', 'Dataset007_Pancreas', 'Dataset008_HepaticVessel', 'Dataset010_Colon', 'Dataset006_Lung', 'Dataset003_Liver'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d7c8239-8afa-4e57-881b-db54cba92844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'val'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['Dataset009_Spleen'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3765a1b5-fa45-44fd-ad18-1efeac90a31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic['Dataset009_Spleen']['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9af4c30c-1f6f-431b-a60e-6365cb2d43d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic['Dataset009_Spleen']['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf7f1e29-e664-4914-aba4-968d077c13ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1653.47it/s]\n"
     ]
    }
   ],
   "source": [
    "for fold in tqdm.tqdm(os.listdir(nnunet_preprocessed)):\n",
    "    if new_name2 in fold:\n",
    "        fold_path = os.path.join(nnunet_preprocessed,fold)\n",
    "        splits_path = os.path.join(fold_path,'splits_final.json')\n",
    "        to_save = [dic[fold]]\n",
    "        with open(splits_path,'w') as f:\n",
    "            json.dump(to_save,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c440ffe9-56b9-4194-9299-d02876d1123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to add modlaity indexes to the testing dataset of different CT organs\n",
    "nnunet_raw = '/blue/kgong/s.kapoor/language_guided_segmentation/CLIP-Driven-Universal-Model_MSD_only/nnUNet_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd99ab51-e311-453d-a128-794fcc1780a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_name2 = 'Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a051639-e78f-4c15-9c86-0b4b0a037504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 20.43it/s]\n"
     ]
    }
   ],
   "source": [
    "#now add _0000 to eachfile name cause modality.\n",
    "des_fold = 'imagesTs'\n",
    "for fold in tqdm.tqdm(os.listdir(nnunet_raw)):\n",
    "    if new_name2 in fold:\n",
    "        fold_path = os.path.join(nnunet_raw,fold)\n",
    "        for subfold in os.listdir(fold_path):\n",
    "            if not subfold.startswith('.') and des_fold in subfold:\n",
    "                subfold_path = os.path.join(fold_path,subfold)\n",
    "                for filename in os.listdir(subfold_path):\n",
    "                    new_filename = filename[:-7]+'_0000.nii.gz'\n",
    "                    filename_path = os.path.join(subfold_path,filename)\n",
    "                    new_filename_path = os.path.join(subfold_path,new_filename)\n",
    "                    #print(filename_path,new_filename_path)\n",
    "                    os.rename(filename_path,new_filename_path)\n",
    "                    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d9e6683-a241-4a44-96ca-b90dce7b597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf2f15-57ac-4642-bc51-98e250835afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
